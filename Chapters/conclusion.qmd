# Conclusion

In this dissertation I have shown evidence that both frequency and predictability lead to multi-word phrases being stored. Further, I have demonstrated that stored items can lose part of their internal structure as a function of usage. Additionally, I have demonstrated that large language models trade off between stored and generative knowledge in ways that are both similar and dissimilar to humans. Finally, I have demonstrated that positing multi-word storage can account for certain features of language change, specifically frequency-dependent preference extremity.

I have also argued that theories of processing and learning must account for multi-word storage. Many of the processing theories today still assume, either explicitly or implicitly, that each sentence is broken down into individual words that are then combined using knowledge of the grammar. However, positing multi-word holistic storage will lead to a new, rich set of predictions and questions.

At the beginning of this dissertation, I posited three questions: 1) what factors determine whether a phrase is stored holistically or generated compositionally? 2) What are the processing consequences for holistic storage? And 3) How are holistically stored phrases represented? In this section, I return to each of the questions and explore what we've learned. I will then explore future questions and what their answers may tell us.

## Revisiting our questions

In this dissertation I have presented evidence that both frequency and predictability drive storage. I have shown, for example, that *up* is harder for participants to recognize in high-frequency or high-predictability phrases than in medium-frequency or medium-predictability phrases. I have also shown that models of learning (large language models) predict that learners rely on item-specific knowledge for binomials that they have experienced before. Further, they also predict that the representations of high-frequency binomials diverge more from their compositional representations than low-frequency binomials.

Additionally, I demonstrated that holistically stored representations cannot be accessed after hearing only the first word in the phrase. In other words, it is possible that participants don't access the phrase until they have enough acoustic information to disambiguate between the phrase and its competitors. Further, I argue that the representation of the phrase competes with the representations of the individual words, causing a slowdown in recognition time for the individual words that comprise the phrase.

Finally, in this dissertation I have argued that storage arises naturally as a function of our learning mechanisms. However, what are the implications of this for language learning and processing more broadly. In the next section I discuss the future of these questions and why the field should care.

## What is next?

Both frequency and predictability drive storage. However, what does this mean? Are they two measurements of the same underlying cognitive process? Indeed, frequency effects are often attributed to automatization while predictability effects are often attributed to learning. For example, as people perform a sequence of motor actions more often (i.e., as they become more frequent), humans become able to perform the sequence more quickly and more fluidly [@sosnik2004whenpracticeleads]. It is possible that frequency effects on storage are a result of a similar process: as people use a phrase more often, it becomes more automatic and this results in it being stored separately.

On the other hand, learners are not simply sensitive to how frequent a cue occurs with an outcome, but also to how predictive a cue is of an outcome [e.g., @ramscarChildrenValueInformativity2013]. Thus, it is possible that rather than automatization, predictability drives storage because predictable things are simply learned as a single chunk.

Future work will do well to examine whether this prediction is born out. For example, according to this account, it seems plausible that frequency effects may lead to storage of a phrase over time as it becomes used more often, while predictability should lead to storage immediately due to learning the phrase as a single unit.

Additionally, very few theories of processing expressly account for multi-word storage [c.f., fragment grammar theories; e.g., @odonnellFragmentGrammarsExploring2009; @morganFormalizingConstructionGrammar]. This is important because most phrases that are stored holistically can also be formed compositionally. That is, storing the phrase *I don't know* holistically does not preclude the learner from generating the phrase compositionally. When do humans access the holistic representation instead of generating it compositionally from its component parts? This is not an easy question and may vary as a function of the task that people are engaging in. It seems more likely that someone would access the phrase holistically in production than perception, for example, because in production the speaker has a meaning they wish to convey. However, in perception it is less clear. For example, when listening to a sentence, the listener must by definition listen in a temporally linear manner (i.e., word-by-word). As such, does the listener wait until hearing the phrase before accessing any of the parts?

Finally, what role will transformer models play in future work on language learning and processing? First, as I have argued in this dissertation, (transformer) language models are the first models of language that we have seen are able to produce fluent, human-like text. However, there are other important reasons to take a closer look at these models as well. First, they learn in a way that resembles, to some extent, human-learning. Specifically, the learning mechanism in both humans and language models is prediction-error. In other words, language models are a model of language learning.

However, it is also the case that there are significant differences between humans and language models. For example, language models require a lot more data than humans.[^conclusion-1] This difference in the amount of data that language models and humans experience has been a source of a great deal of criticism. However, there have been recent attempts to bridge this gap. For example, several recent studies have taken the initiative of training smaller language models [e.g., @misraLanguageModelsLearn2024; @yaoBothDirectIndirect2025] using an amount of data comparable to humans. This method allows for more direct comparisons between models and human behavioral studies because it allows for complete control over the models training and testing environments. By manipulating the training data of language models, it is possible to more carefully examine what factors affect the trade off between computation and storage.

[^conclusion-1]: Although I have made the case through this dissertation that this is not a fair comparison, given that each encounter a human has with a word contains a great deal of contextual information that language models don't get, such as visual and audio cues.
