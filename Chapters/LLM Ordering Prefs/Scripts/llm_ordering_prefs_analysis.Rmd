---
title: "Analysis"
author: "Zach"
date: "2024-02-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(mgcv)
library(ggpubr)
library(tidybayes)

corpus = read_csv('../Data/corpus.csv')
```

# Analysis

Within this script will be the analyses for the study about ordering preferences in LLMs.

We care about how the effects of generative preferences and observed (relative) frequency change as a function of the overall frequency of the binomial.

This script will be divided into two main sections:

1.  The analyses for just the binomial (*cat and dog*)
2.  The analyses for the binomial within a sentence context*.*

We will run analyses for reading times and 2afc task. 2afc task is operationalized here as the sum of the log probabilities across all words in the sentence. Reading time is operationalized as the sum of the log probabilities across our target region, consists of 6 words: the first word in the binomial to the 6th word after.

## Just Binomials

### 2afc

Technically, for just binomials, 2afc = reading times. Since 2afc is the probability of the sentence (sum of log probs for each item in the sentence), and reading times are the probability of a specific region in the sentence (sum of log probs for each item in a given region of the sentence).

In this case, the entire sentence is the region we care about. Thus for just binomials we run only one task for each language model.

Our main analyses will be:

$$
logit(P_{AandB}) \sim GenPref + OrderingPref + Overall Freq + OverallFreq \colon GenPref + OverallFreq \colon OrderingPref
$$

Where our dependent variable is the probability of the binomial being alphabetical form.

And the independent variables are the generative preference of a given binomial, the ordering preference, the overall frequency, and the interaction between overall frequency and generative preference as well as the interaction between overall frequency and the ordering preference.

We don't need a random intercept for item because we have one observation for each item, so this would be meaningless.

We also don't need a random intercept for "subject" because we don't have any subjects.

<!--# do we have no random effects here?? Surely I'm forgetting something -->

#### GPT2

Load data:

```{r}
gpt2_data_just_binoms = read_csv('../Data/gpt2_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Quick and dirty historgram:

```{r}
# ggplot(data = gpt2_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = gpt2xl_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = llama7b_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = llama13b_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = corpus, aes(x=RelFreq, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
```

Analysis:

```{r}
prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

gpt2_2afc_model_just_binoms = brm(data = gpt2_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2_2afc_model_just_binoms'
                      )

fixef(gpt2_2afc_model_just_binoms)

# mcmc_plot(
#   gpt2_2afc_model_just_binoms,
#   type = 'pairs',
#   off_diag_fun = 'hex',
#   diag_fun = 'dens',
#   fixed = T
# )
```

Checking posterior samples:

```{r}
post_samples_gpt2 = as.data.frame(fixef(gpt2_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_gpt2$GenPref < 0) / length(post_samples_gpt2$GenPref)
  
post_samples_genpref_freq = sum(post_samples_gpt2$`GenPref:OverallFreq` < 0) / length(post_samples_gpt2$`GenPref:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)
```

#### GPT2-XL

Load data:

```{r}
gpt2xl_data_just_binoms = read_csv('../Data/gpt2xl_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)


```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))

gpt2xl_2afc_model_just_binoms = brm(data = gpt2xl_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2xl_2afc_model_just_binoms'
                      )

fixef(gpt2xl_2afc_model_just_binoms)
```

Checking posterior samples for some of the effects:

```{r}
post_samples_gpt2xl = as.data.frame(fixef(gpt2xl_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_gpt2xl$GenPref < 0) / length(post_samples_gpt2xl$GenPref)
  
post_samples_genpref_freq = sum(post_samples_gpt2xl$`GenPref:OverallFreq` < 0) / length(post_samples_gpt2xl$`GenPref:OverallFreq`)

# post_samples_relfreq_freq = sum(post_samples_gpt2$`RelFreq:OverallFreq` > 0) / length(post_samples_gpt2$`RelFreq:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)

```

#### Llama-7b

Load data:

```{r}
llama7b_data_just_binoms = read_csv('../Data/llama7b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))

llama7b_2afc_model_just_binoms = brm(data = llama7b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama7b_2afc_model_just_binoms'
                      )

fixef(llama7b_2afc_model_just_binoms)
```

Checking posterior:

```{r}
post_samples_llama7b = as.data.frame(fixef(llama7b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_llama7b$GenPref < 0) / length(post_samples_llama7b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama7b$`GenPref:OverallFreq` < 0) / length(post_samples_llama7b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama7b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama7b$`RelFreq:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama-13b Unquantized

Load data:

```{r}
llama13b_unquantized_data_just_binoms = read_csv('../Data/llama13b_unquantized_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama13b_unquantized_data_just_binoms = llama13b_unquantized_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama13b_unquantized_data_just_binoms = llama13b_unquantized_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  mutate(gen_rel_diff = GenPref - RelFreq)


```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_unquantized_2afc_model_just_binoms = brm(data = llama13b_unquantized_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_unquantized_2afc_model_just_binoms'
                      )

fixef(llama13b_unquantized_2afc_model_just_binoms)
```

Checking posterior:

```{r}
post_samples_llama13b = as.data.frame(fixef(llama13b_unquantized_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama13b$`GenPref:OverallFreq` < 0) / length(post_samples_llama13b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama13b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama13b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama13B

Load data:

```{r}
llama13b_data_just_binoms = read_csv('../Data/llama13b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  mutate(gen_rel_diff = GenPref - RelFreq)

# 
# llama13b_sim2 = read_csv('../Data/llama13b_s5.csv') %>%
#   separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
#   select(-and) 
# 
# 
# llama13b_sim2 = llama13b_sim2 %>%
#   mutate(WordA = tolower(WordA), WordB = tolower(WordB))
# 
# llama13b_sim2 = llama13b_sim2 %>%
#   left_join(corpus) %>%
#   mutate(log_freq = log(OverallFreq)) %>%
#   mutate(OverallFreq = log_freq - mean(log_freq)) %>%
#   mutate(GenPref = GenPref - 0.5) %>%
#   mutate(RelFreq = RelFreq - 0.5) %>%
#   mutate(gen_rel_diff = GenPref - RelFreq)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_2afc_model_just_binoms = brm(data = llama13b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_2afc_model_just_binoms'
                      )

fixef(llama13b_2afc_model_just_binoms)
# 
# options(contrasts = c("contr.sum","contr.sum"))
# llama13b_2afc_model_just_binoms_sim2 = brm(data = llama13b_sim2,
#                        log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
#                        prior = prior_probs,
#                        iter = 20000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        control = list(max_treedepth = 20),
#                        file = '../Data/llama13b_2afc_model_just_binoms_sim5'
#                       )
# 
# fixef(llama13b_2afc_model_just_binoms_sim2)
```

Checking posterior:

```{r}
post_samples_llama13b = as.data.frame(fixef(llama13b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama13b$`GenPref:OverallFreq` < 0) / length(post_samples_llama13b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama13b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama13b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

##### Plot of quantized vs unquantized results

```{r}
quant_unquantized_plot_data = llama13b_data_just_binoms %>%
  mutate(unquantized_probs = llama13b_unquantized_data_just_binoms$log_odds)

ggplot(data = quant_unquantized_plot_data) +
  geom_point(aes(x = log_odds, y = unquantized_probs))
  

```

#### Llama 13b Bits and bytes

Load data:

```{r}
llama13b_data_just_binoms = read_csv('../Data/llama13b_bitsandbytes_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  mutate(gen_rel_diff = GenPref - RelFreq)

# 
# llama13b_sim2 = read_csv('../Data/llama13b_s5.csv') %>%
#   separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
#   select(-and) 
# 
# 
# llama13b_sim2 = llama13b_sim2 %>%
#   mutate(WordA = tolower(WordA), WordB = tolower(WordB))
# 
# llama13b_sim2 = llama13b_sim2 %>%
#   left_join(corpus) %>%
#   mutate(log_freq = log(OverallFreq)) %>%
#   mutate(OverallFreq = log_freq - mean(log_freq)) %>%
#   mutate(GenPref = GenPref - 0.5) %>%
#   mutate(RelFreq = RelFreq - 0.5) %>%
#   mutate(gen_rel_diff = GenPref - RelFreq)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_2afc_model_just_binoms = brm(data = llama13b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_bitsandbytes_2afc_model_just_binoms'
                      )

fixef(llama13b_2afc_model_just_binoms)

# options(contrasts = c("contr.sum","contr.sum"))
# llama13b_2afc_model_just_binoms_sim2 = brm(data = llama13b_sim2,
#                        log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
#                        prior = prior_probs,
#                        iter = 20000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        control = list(max_treedepth = 20),
#                        file = '../Data/llama13b_2afc_model_just_binoms_sim5'
#                       )
# 
# fixef(llama13b_2afc_model_just_binoms_sim2)
```

Checking posterior:

```{r}
post_samples_llama13b = as.data.frame(fixef(llama13b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama13b$`GenPref:OverallFreq` < 0) / length(post_samples_llama13b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama13b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama13b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama3 8b

Load data:

```{r}
llama3_8b_data_just_binoms = read_csv('../Data/llama3_8b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama3_8b_data_just_binoms = llama3_8b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama3_8b_data_just_binoms = llama3_8b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama3_8b_2afc_model_just_binoms = brm(data = llama3_8b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_8b_2afc_model_just_binoms'
                      )

fixef(llama3_8b_2afc_model_just_binoms)

llama3_8b_2afc_model_only_genpref = brm(data = llama3_8b_data_just_binoms,
                       log_odds ~ GenPref,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_8b_2afc_model_only_genpref'
                      )

fixef(llama3_8b_2afc_model_only_genpref)

llama3_simple_model = brm(data = llama3_8b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_8b_simple_model_just_binoms'
                      )

fixef(llama3_simple_model)

```

Checking posterior:

```{r}
post_samples_llama3_8b = as.data.frame(fixef(llama3_8b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama3_8b$`GenPref:OverallFreq` < 0) / length(post_samples_llama3_8b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama3_8b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama3_8b$`RelFreq:OverallFreq`)

post_samples_genpref = sum(post_samples_llama3_8b$`GenPref` < 0) / length(post_samples_llama3_8b$`GenPref`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
print(post_samples_genpref)

```

#### Lama2 70B

```{r}
llama2_70b_data_just_binoms = read_csv('../Data/llama70b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama2_70b_data_just_binoms = llama2_70b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama2_70b_data_just_binoms = llama2_70b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama_70b_2afc_model_just_binoms = brm(data = llama2_70b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama_70b_2afc_model_just_binoms'
                      )

fixef(llama_70b_2afc_model_just_binoms)

llama_70b_2afc_model_only_genpref = brm(data = llama2_70b_data_just_binoms,
                       log_odds ~ GenPref,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama_70b_2afc_model_only_genpref'
                      )

fixef(llama_70b_2afc_model_only_genpref)
```

#### Llama2 70B GPTQ

```{r}
llama2_70bgptq_data_just_binoms = read_csv('../Data/llama70b_gptq.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama2_70bgptq_data_just_binoms = llama2_70bgptq_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama2_70bgptq_data_just_binoms = llama2_70bgptq_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama_70bgptq_2afc_model_just_binoms = brm(data = llama2_70bgptq_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama_70bgptq_2afc_model_just_binoms'
                      )

fixef(llama_70bgptq_2afc_model_just_binoms)

```

#### Lama3 70B

```{r}
llama3_70b_data_just_binoms = read_csv('../Data/llama3_70b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama3_70b_data_just_binoms = llama3_70b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama3_70b_data_just_binoms = llama3_70b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama3_70b_2afc_model_just_binoms = brm(data = llama3_70b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_70b_2afc_model_just_binoms'
                      )

fixef(llama3_70b_2afc_model_just_binoms)

llama3_70b_2afc_model_only_genpref = brm(data = llama3_70b_data_just_binoms,
                       log_odds ~ GenPref,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_70b_2afc_model_only_genpref'
                      )

fixef(llama3_70b_2afc_model_only_genpref)

llama3_70B_simple_model = brm(data = llama3_70b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_70b_simple_model_just_binoms'
                      )

fixef(llama3_70B_simple_model)
```

Post-samples:

```{r}
post_samples_llama3_70b = as.data.frame(fixef(llama3_70b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama3_70b$`GenPref:OverallFreq` < 0) / length(post_samples_llama3_70b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama3_70b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama3_70b$`RelFreq:OverallFreq`)

post_samples_genpref = sum(post_samples_llama3_70b$`GenPref` > 0) / length(post_samples_llama3_70b$`GenPref`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
print(post_samples_genpref)
```

#### Phi-3

Load data:

```{r}
phi3_data_just_binoms = read_csv('../Data/phi3_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

phi3_data_just_binoms = phi3_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

phi3_data_just_binoms = phi3_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
phi3_2afc_model_just_binoms = brm(data = phi3_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/phi3_2afc_model_just_binoms'
                      )

fixef(phi3_2afc_model_just_binoms)
```

Checking posterior:

```{r}
post_samples_phi3 = as.data.frame(fixef(phi3_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_phi3$`GenPref:OverallFreq` < 0) / length(post_samples_phi3$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_phi3$`RelFreq:OverallFreq` < 0) / length(post_samples_phi3$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Yi 34b

```{r}
yi34b_data_just_binoms = read_csv('../Data/yi34b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

yi34b_data_just_binoms = yi34b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

yi34b_data_just_binoms = yi34b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
yi34b_2afc_model_just_binoms = brm(data = yi34b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/yi34b_2afc_model_just_binoms'
                      )

fixef(yi34b_2afc_model_just_binoms)
```

```{r}
post_samples_yi34b = as.data.frame(fixef(yi34b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_yi34b$GenPref > 0) / length(post_samples_yi34b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_yi34b$`GenPref:OverallFreq` > 0) / length(post_samples_yi34b$`GenPref:OverallFreq`)

#post_samples_relfreq_freq = sum(post_samples_yi34b$`RelFreq:OverallFreq` < 0) / length(post_samples_yi34b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_genpref)
```

#### Yi 1.5 9B

```{r}
yi1.5_9b_data_just_binoms = read_csv('../Data/yi1.5_9b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

yi1.5_9b_data_just_binoms = yi1.5_9b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

yi1.5_9b_data_just_binoms = yi1.5_9b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
yi1.5_9b_2afc_model_just_binoms = brm(data = yi1.5_9b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/yi1.5_9b_2afc_model_just_binoms'
                      )

fixef(yi1.5_9b_2afc_model_just_binoms)
```

```{r}
post_samples_yi9b = as.data.frame(fixef(yi1.5_9b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_yi9b$GenPref > 0) / length(post_samples_yi9b$GenPref)

post_samples_genpref
 
```

#### Falcon 7b

```{r}
falcon_7b_just_binoms = read_csv('../Data/falcon7b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_7b_just_binoms = falcon_7b_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_7b_just_binoms = falcon_7b_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon7b_2afc_model_just_binoms = brm(data = falcon_7b_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon7b_2afc_model_just_binoms'
                      )

fixef(falcon7b_2afc_model_just_binoms)
```

```{r}
post_samples_falcon7b = as.data.frame(fixef(falcon7b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon7b$GenPref > 0) / length(post_samples_falcon7b$GenPref)

post_samples_genpref
 
```

#### Falcon 11b

```{r}
falcon_11b_just_binoms = read_csv('../Data/falcon11b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_11b_just_binoms = falcon_11b_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_11b_just_binoms = falcon_11b_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon11b_2afc_model_just_binoms = brm(data = falcon_11b_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon11b_2afc_model_just_binoms'
                      )

fixef(falcon11b_2afc_model_just_binoms)
```

```{r}
post_samples_falcon11b = as.data.frame(fixef(falcon11b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon11b$GenPref > 0) / length(post_samples_falcon11b$GenPref)

post_samples_genpref
 
```

#### Falcon 40b

```{r}
falcon_40b_just_binoms = read_csv('../Data/falcon40b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_40b_just_binoms = falcon_40b_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_40b_just_binoms = falcon_40b_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```


Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon40b_2afc_model_just_binoms = brm(data = falcon_40b_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon40b_2afc_model_just_binoms'
                      )

fixef(falcon40b_2afc_model_just_binoms)
```

```{r}
post_samples_falcon40b = as.data.frame(fixef(falcon40b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon40b$GenPref > 0) / length(post_samples_falcon40b$GenPref)

post_samples_genpref
 
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon180b_2afc_model_just_binoms = brm(data = falcon_180b_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon180b_2afc_model_just_binoms'
                      )

fixef(falcon180b_2afc_model_just_binoms)
```

```{r}
post_samples_falcon180b = as.data.frame(fixef(falcon180b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon180b$GenPref > 0) / length(post_samples_falcon180b$GenPref)

post_samples_genpref
 
```

## Sentence Context

Same analyses as above but within a sentence context

Load data:

```{r}
gpt2_data_just_binoms = read_csv('../Data/gpt2_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Quick and dirty historgram:

```{r}
# ggplot(data = gpt2_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = gpt2xl_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = llama7b_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = llama13b_data_just_binoms, aes(x=ProbAandB, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
# 
# ggplot(data = corpus, aes(x=RelFreq, y = ..density..)) +
#   geom_histogram() +
#   theme_bw()
```

Analysis:

```{r}
prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

gpt2_2afc_model_just_binoms = brm(data = gpt2_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2_2afc_model_just_binoms'
                      )

fixef(gpt2_2afc_model_just_binoms)

# mcmc_plot(
#   gpt2_2afc_model_just_binoms,
#   type = 'pairs',
#   off_diag_fun = 'hex',
#   diag_fun = 'dens',
#   fixed = T
# )
```

Checking posterior samples:

```{r}
post_samples_gpt2 = as.data.frame(fixef(gpt2_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_gpt2$GenPref < 0) / length(post_samples_gpt2$GenPref)
  
post_samples_genpref_freq = sum(post_samples_gpt2$`GenPref:OverallFreq` < 0) / length(post_samples_gpt2$`GenPref:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)
```

#### GPT2-XL

Load data:

```{r}
gpt2xl_data = read_csv('../Data/gpt2xl_2afc_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)


```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))

gpt2xl_2afc_model = brm(data = gpt2xl_data,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/gpt2xl_2afc_model'
                      )

fixef(gpt2xl_2afc_model)
```

Checking posterior samples for some of the effects:

```{r}
post_samples_gpt2xl = as.data.frame(fixef(gpt2xl_2afc_model, summary = F))

post_samples_genpref = sum(post_samples_gpt2xl$GenPref < 0) / length(post_samples_gpt2xl$GenPref)
  
post_samples_genpref_freq = sum(post_samples_gpt2xl$`GenPref:OverallFreq` < 0) / length(post_samples_gpt2xl$`GenPref:OverallFreq`)

# post_samples_relfreq_freq = sum(post_samples_gpt2$`RelFreq:OverallFreq` > 0) / length(post_samples_gpt2$`RelFreq:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)

```

#### Llama-7b

Load data:

```{r}
llama7b_data = read_csv('../Data/llama7b_2afc_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))

llama7b_2afc_model = brm(data = llama7b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama7b_2afc_model'
                      )

fixef(llama7b_2afc_model)
```

Checking posterior:

```{r}
post_samples_llama7b = as.data.frame(fixef(llama7b_2afc_model, summary = F))

post_samples_genpref = sum(post_samples_llama7b$GenPref < 0) / length(post_samples_llama7b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama7b$`GenPref:OverallFreq` < 0) / length(post_samples_llama7b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama7b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama7b$`RelFreq:OverallFreq`)

print(post_samples_genpref)
print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama-13b

Load data:

```{r}
llama13b_data = read_csv('../Data/llama13b_2afc_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and)  %>%
  mutate(log_odds = `Alpha Probs` - `Nonalpha Probs`)

llama13b_data = llama13b_data %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama13b_data = llama13b_data %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  mutate(gen_rel_diff = GenPref - RelFreq)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_2afc_model = brm(data = llama13b_data,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_2afc_model'
                      )

fixef(llama13b_2afc_model)
```

Checking posterior:

```{r}
post_samples_llama13b = as.data.frame(fixef(llama13b_2afc_model, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama13b$`GenPref:OverallFreq` < 0) / length(post_samples_llama13b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama13b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama13b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama13B unquantized

Load data:

```{r}
llama13b_unquantized_data = read_csv('../Data/llama13b_unquantized_2afc_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama13b_unquantized_data = llama13b_unquantized_data %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama13b_unquantized_data = llama13b_unquantized_data %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  mutate(gen_rel_diff = GenPref - RelFreq)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama13b_unquantized_2afc_model = brm(data = llama13b_unquantized_data,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama13b_unquantized_2afc_model'
                      )

fixef(llama13b_unquantized_2afc_model)
```

Checking posterior:

```{r}
post_samples_llama13b = as.data.frame(fixef(llama13b_unquantized_2afc_model, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama13b$`GenPref:OverallFreq` < 0) / length(post_samples_llama13b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama13b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama13b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Llama3 8b

Load data:

```{r}
llama3_8b_data_just_binoms = read_csv('../Data/llama3_8b_2afc_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama3_8b_data_just_binoms = llama3_8b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama3_8b_data_just_binoms = llama3_8b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama3_8b_2afc_model_just_binoms = brm(data = llama3_8b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_8b_2afc_model_just_binoms'
                      )

fixef(llama3_8b_2afc_model_just_binoms)

llama3_8b_2afc_model_only_genpref = brm(data = llama3_8b_data_just_binoms,
                       log_odds ~ GenPref,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_8b_2afc_model_only_genpref'
                      )

fixef(llama3_8b_2afc_model_only_genpref)

llama3_simple_model = brm(data = llama3_8b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_8b_simple_model_just_binoms'
                      )

fixef(llama3_simple_model)

```

Checking posterior:

```{r}
post_samples_llama3_8b = as.data.frame(fixef(llama3_8b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama3_8b$`GenPref:OverallFreq` < 0) / length(post_samples_llama3_8b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama3_8b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama3_8b$`RelFreq:OverallFreq`)

post_samples_genpref = sum(post_samples_llama3_8b$`GenPref` < 0) / length(post_samples_llama3_8b$`GenPref`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
print(post_samples_genpref)

```

#### Lama2 70B

```{r}
llama2_70b_data_just_binoms = read_csv('../Data/llama70b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama2_70b_data_just_binoms = llama2_70b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama2_70b_data_just_binoms = llama2_70b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama_70b_2afc_model_just_binoms = brm(data = llama2_70b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama_70b_2afc_model_just_binoms'
                      )

fixef(llama_70b_2afc_model_just_binoms)

llama_70b_2afc_model_only_genpref = brm(data = llama2_70b_data_just_binoms,
                       log_odds ~ GenPref,
                       prior = prior_probs,
                       iter = 20000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama_70b_2afc_model_only_genpref'
                      )

fixef(llama_70b_2afc_model_only_genpref)
```

#### Llama2 70B GPTQ

#### Lama3 70B

```{r}
llama3_70b_data_just_binoms = read_csv('../Data/llama3_70b_2afc_just_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

llama3_70b_data_just_binoms = llama3_70b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

llama3_70b_data_just_binoms = llama3_70b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

```{r}
options(contrasts = c("contr.sum","contr.sum"))
llama3_70b_2afc_model_just_binoms = brm(data = llama3_70b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/llama3_70b_2afc_model'
                      )

fixef(llama3_70b_2afc_model_just_binoms)

```

Post-samples:

```{r}
post_samples_llama3_70b = as.data.frame(fixef(llama3_70b_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_llama3_70b$`GenPref:OverallFreq` < 0) / length(post_samples_llama3_70b$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_llama3_70b$`RelFreq:OverallFreq` < 0) / length(post_samples_llama3_70b$`RelFreq:OverallFreq`)

post_samples_genpref = sum(post_samples_llama3_70b$`GenPref` > 0) / length(post_samples_llama3_70b$`GenPref`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
print(post_samples_genpref)
```

#### Phi-3

Load data:

```{r}
phi3_data_just_binoms = read_csv('../Data/phi3_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

phi3_data_just_binoms = phi3_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

phi3_data_just_binoms = phi3_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)
```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
phi3_2afc_model_just_binoms = brm(data = phi3_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/phi3_2afc_model_just_binoms'
                      )

fixef(phi3_2afc_model_just_binoms)
```

Checking posterior:

```{r}
post_samples_phi3 = as.data.frame(fixef(phi3_2afc_model_just_binoms, summary = F))

# post_samples_genpref = sum(post_samples_llama13b$GenPref < 0) / length(post_samples_llama13b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_phi3$`GenPref:OverallFreq` < 0) / length(post_samples_phi3$`GenPref:OverallFreq`)

post_samples_relfreq_freq = sum(post_samples_phi3$`RelFreq:OverallFreq` < 0) / length(post_samples_phi3$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_relfreq_freq)
```

#### Yi 34b

```{r}
yi34b_data_just_binoms = read_csv('../Data/yi34b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

yi34b_data_just_binoms = yi34b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

yi34b_data_just_binoms = yi34b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
yi34b_2afc_model_just_binoms = brm(data = yi34b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/yi34b_2afc_model'
                      )

fixef(yi34b_2afc_model_just_binoms)
```

```{r}
post_samples_yi34b = as.data.frame(fixef(yi34b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_yi34b$GenPref > 0) / length(post_samples_yi34b$GenPref)
  
post_samples_genpref_freq = sum(post_samples_yi34b$`GenPref:OverallFreq` > 0) / length(post_samples_yi34b$`GenPref:OverallFreq`)

#post_samples_relfreq_freq = sum(post_samples_yi34b$`RelFreq:OverallFreq` < 0) / length(post_samples_yi34b$`RelFreq:OverallFreq`)

print(post_samples_genpref_freq)
print(post_samples_genpref)
```

#### Yi 1.5 9B

```{r}
yi1.5_9b_data_just_binoms = read_csv('../Data/yi1.5_9b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

yi1.5_9b_data_just_binoms = yi1.5_9b_data_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

yi1.5_9b_data_just_binoms = yi1.5_9b_data_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
yi1.5_9b_2afc_model_just_binoms = brm(data = yi1.5_9b_data_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/yi1.5_9b_2afc_model_just_binoms'
                      )

fixef(yi1.5_9b_2afc_model_just_binoms)
```

```{r}
post_samples_yi9b = as.data.frame(fixef(yi1.5_9b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_yi9b$GenPref > 0) / length(post_samples_yi9b$GenPref)

post_samples_genpref
 
```

#### Falcon 7b

```{r}
falcon_7b = read_csv('../Data/falcon7b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_7b = falcon_7b %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_7b = falcon_7b %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon7b_2afc_model = brm(data = falcon_7b,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon7b_2afc_model'
                      )

fixef(falcon7b_2afc_model)
```

```{r}
post_samples_falcon7b = as.data.frame(fixef(falcon7b_2afc_model, summary = F))

post_samples_genpref = sum(post_samples_falcon7b$GenPref > 0) / length(post_samples_falcon7b$GenPref)

post_samples_genpref
 
```

#### Falcon 11b

```{r}
falcon_11b = read_csv('../Data/falcon11b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_11b = falcon_11b %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_11b = falcon_11b %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon11b_2afc_model = brm(data = falcon_11b,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon11b_2afc_model'
                      )

fixef(falcon11b_2afc_model)
```

```{r}
post_samples_falcon11b = as.data.frame(fixef(falcon11b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon11b$GenPref > 0) / length(post_samples_falcon11b$GenPref)

post_samples_genpref
 
```

#### Falcon 40b

```{r}
falcon_40b_just_binoms = read_csv('../Data/falcon40b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_40b_just_binoms = falcon_40b_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_40b_just_binoms = falcon_40b_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon40b_2afc_model_just_binoms = brm(data = falcon_40b_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon40b_2afc_model_just_binoms'
                      )

fixef(falcon40b_2afc_model_just_binoms)
```

```{r}
post_samples_falcon40b = as.data.frame(fixef(falcon40b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon40b$GenPref > 0) / length(post_samples_falcon40b$GenPref)

post_samples_genpref
 
```

#### Falcon 180b

```{r}
falcon_180b_just_binoms = read_csv('../Data/falcon180b_2afc_binom_ordering_prefs.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) 

falcon_180b_just_binoms = falcon_180b_just_binoms %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB))

falcon_180b_just_binoms = falcon_180b_just_binoms %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

```

Analysis:

```{r}
options(contrasts = c("contr.sum","contr.sum"))
falcon180b_2afc_model_just_binoms = brm(data = falcon_180b_just_binoms,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/falcon180b_2afc_model_just_binoms'
                      )

fixef(falcon180b_2afc_model_just_binoms)
```

```{r}
post_samples_falcon180b = as.data.frame(fixef(falcon180b_2afc_model_just_binoms, summary = F))

post_samples_genpref = sum(post_samples_falcon180b$GenPref > 0) / length(post_samples_falcon180b$GenPref)

post_samples_genpref
 
```

## Olmo Models

### 1B Model

#### Step20000 - 86B tokens

```{python}
#from huggingface_hub import list_repo_refs

#out = list_repo_refs("allenai/OLMo-7B")
#branches = [b.name for b in out.branches]
```

```{r}
olmo1b_20000_86B = read_csv('../Data/olmo1b_step20000_tokens84B.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)


prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo1b_20000_86B_model = brm(data = olmo1b_20000_86B,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/olmo1b_20000_86B'
                      )

fixef(olmo1b_20000_86B_model)
```

#### Step30000 - 126B Tokens

```{r}
olmo1b_30000_126B = read_csv('../Data/olmo1b_step30000_tokens126B.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo1b_30000_126B_model = brm(data = olmo1b_30000_126B,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo1b_30000_126B'
                      )

fixef(olmo1b_30000_126B_model)
```

#### Step 4000 168B Tokens

```{r}
olmo1b_40000_168B = read_csv('../Data/olmo1b_step40000_tokens168B.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo1b_40000_168B_model = brm(data = olmo1b_40000_168B,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo1b_40000_168B'
                      )

fixef(olmo1b_40000_168B_model)
```

#### Full Model

```{r}
olmo1b_main = read_csv('../Data/olmo1b_main.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)


prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo1b_main_model = brm(data = olmo1b_main,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo1b_main'
                      )



fixef(olmo1b_main_model)

post_samples_olmo1b = as.data.frame(fixef(olmo1b_main_model, summary = F))
post_samples_genpref = sum(post_samples_olmo1b$GenPref < 0) / length(post_samples_olmo1b$GenPref)
post_samples_genpref
```

### 7B Model

#### Step20000 - 84B tokens

```{python}
#from huggingface_hub import list_repo_refs

#out = list_repo_refs("allenai/OLMo-7B")
#branches = [b.name for b in out.branches]
```

```{r}
olmo7b_20000_86B = read_csv('../Data/olmo7b_step20000_tokens84B.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)


prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo7b_20000_86B_model = brm(data = olmo7b_20000_86B,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo7b_20000_86B'
                      )

fixef(olmo7b_20000_86B_model)
```

#### Step30000 - 126B Tokens

```{r}
olmo7b_30000_126B = read_csv('../Data/olmo7b_step30000_tokens128B.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo7b_30000_126B_model = brm(data = olmo7b_30000_126B,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo7b_30000_126B'
                      )

fixef(olmo7b_30000_126B_model)
```

#### Step 40000 168B Tokens

```{r}
olmo7b_40000_168B = read_csv('../Data/olmo7b_step40000_tokens168B.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)

prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo7b_40000_168B_model = brm(data = olmo1b_40000_168B,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo7b_40000_168B'
                      )

fixef(olmo7b_40000_168B_model)
```

#### Full Model

```{r}
olmo7b_main = read_csv('../Data/olmo7b_main.csv') %>%
  separate(binom, c('WordA', 'and', 'WordB'), remove = F, sep = ' ') %>%
  select(-and) %>%
  mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(log_freq = log(OverallFreq)) %>%
  mutate(OverallFreq = log_freq - mean(log_freq)) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5)


prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

options(contrasts = c("contr.sum","contr.sum"))

olmo7b_main_model = brm(data = olmo7b_main,
                       log_odds ~ GenPref + RelFreq + GenPref:OverallFreq + RelFreq:OverallFreq + OverallFreq,
                       prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/olmo7b_main'
                      )

fixef(olmo7b_main_model)


post_samples_olmo7b = as.data.frame(fixef(olmo7b_main_model, summary = F))

post_samples_genpref = sum(post_samples_olmo7b$GenPref < 0) / length(post_samples_olmo7b$GenPref)
post_samples_genpref
```

## Plots

```{r}
library(extrafont) 
#font_import()

# Only three fonts seem to have been imported...
loadfonts(); windowsFonts()

gpt2_df = data.frame(fixef(gpt2_2afc_model_just_binoms))%>%
  mutate(model = 'gpt-2') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])

gpt2xl_df = data.frame(fixef(gpt2xl_2afc_model_just_binoms)) %>%
  mutate(model = 'gpt-2 XL') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])

llama7b_df = data.frame(fixef(llama7b_2afc_model_just_binoms)) %>%
  mutate(model = 'Llama-2 7B') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])

llama13b_df = data.frame(fixef(llama13b_unquantized_2afc_model_just_binoms)) %>%
  mutate(model = 'Llama-2 13B') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])

llama3_8b_df = data.frame(fixef(llama3_8b_2afc_model_just_binoms)) %>%
  mutate(model = 'Llama-3 8B') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])

llama3_70b_df = data.frame(fixef(llama3_70b_2afc_model_just_binoms)) %>%
  mutate(model = 'Llama-3 70B') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])


OlmO_1b_df = data.frame(fixef(olmo1b_main_model)) %>%
  mutate(model = 'OlmO 1B') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])

OlmO_7b_df = data.frame(fixef(olmo7b_main_model)) %>%
  mutate(model = 'OlmO 7B') %>%
  rownames_to_column('Beta Coefficient') %>%
  mutate(Intercept = Estimate[1])


all_models_data = gpt2_df %>%
  full_join(gpt2xl_df) %>%
  full_join(llama7b_df) %>%
  full_join(llama13b_df) %>%
  full_join(llama3_8b_df) %>%
  full_join(llama3_70b_df) %>%
  full_join(OlmO_1b_df) %>%
  full_join(OlmO_7b_df)


gen_pref_plot_data = all_models_data %>%
  filter(`Beta Coefficient` == 'GenPref')

observed_pref_plot_data = all_models_data %>%
  filter(`Beta Coefficient` == 'RelFreq')

gen_pref_plot_data$model = factor(gen_pref_plot_data$model, levels = c('gpt-2', 'OlmO 1B', 'gpt-2 XL', 'Llama-2 7B',  'OlmO 7B', 'Llama-3 8B', 'Llama-2 13B', 'Llama-3 70B'))

observed_pref_plot_data$model = factor(observed_pref_plot_data$model, levels = c('gpt-2', 'OlmO 1B', 'gpt-2 XL', 'Llama-2 7B',  'OlmO 7B', 'Llama-3 8B', 'Llama-2 13B', 'Llama-3 70B'))

gen_pref_plot = ggplot(data = gen_pref_plot_data, aes(x = model, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_errorbar(width = 0.2) +
  geom_point(size = 1.5) +
  theme_bw() +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12,face="bold")) +
  ylim(c(-2.5, 10)) +
  ylab('Beta Coefficient for Generative Preferences') +
  xlab('Language Model')


observed_pref_plot = ggplot(data = observed_pref_plot_data, aes(x = model, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_errorbar(width = 0.2) +
  geom_point(size = 1.5) +
  theme_bw() +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12,face="bold")) +
  ylim(c(-2.5, 10)) +
  ylab('Beta Coefficient for Observed Preferences') +
  xlab('Language Model')
  

gen_pref_plot
#ggsave('../Data/gen_pref_plot.png')
observed_pref_plot
#ggsave('../Data/observed_pref_plot.png')


full_plot_data = all_models_data %>%
  filter(`Beta Coefficient` != 'Intercept') %>%
  mutate(color = ifelse( `Beta Coefficient` == 'GenPref', 'red', ifelse(`Beta Coefficient` == 'RelFreq', 'blue', ifelse(`Beta Coefficient` == 'OverallFreq', 'purple', ifelse(`Beta Coefficient` == 'GenPref:OverallFreq', 'darkgreen', 'orange')))))


full_plot_data$model = factor(full_plot_data$model, levels = c('gpt-2', 'OlmO 1B', 'gpt-2 XL', 'Llama-2 7B',  'OlmO 7B', 'Llama-3 8B', 'Llama-2 13B', 'Llama-3 70B'))

full_plot_data = full_plot_data %>%
  mutate(`Beta Coefficient` = case_when(`Beta Coefficient` == 'GenPref' ~ 'AbsPref',
                                        `Beta Coefficient` == 'GenPref:OverallFreq' ~ 'AbsPref:OverallFreq',
                                        `Beta Coefficient` == 'RelFreq' ~ 'RelFreq',
                                        `Beta Coefficient` == 'OverallFreq' ~ 'OverallFreq',
                                        `Beta Coefficient` == 'RelFreq:OverallFreq' ~ 'RelFreq:OverallFreq'
                                      ))

full_plot_data$`Beta Coefficient` = factor(full_plot_data$`Beta Coefficient`, levels = c('RelFreq', 'AbsPref', 'OverallFreq', 'RelFreq:OverallFreq', 'AbsPref:OverallFreq'))

full_plot = ggplot(data = full_plot_data, aes(x = `Beta Coefficient`, y = Estimate, ymin = Q2.5, ymax = Q97.5, color = color)) +
  geom_errorbar(width = 0.25) +
  geom_point(size = 1.5) +
  facet_wrap(~model, nrow = 2) +
  theme_bw() +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10,face="bold"),
        axis.text.x = element_text(hjust = 0, angle = -45, color = 'black', size = 10),
        axis.text.y = element_text(hjust = 0, color = 'black'),
        legend.position = 'none',
        plot.margin = margin(10, 50, 10, 10),
        aspect.ratio = 2/1.5,
        strip.text.x = element_text(size = 8, color = 'black',face="bold"),
        #panel.background = element_rect(fill = "white"),
        #text = element_text(family = 'Times New Roman')
        ) +
  scale_x_discrete(labels = c(expression('ObsPref'), expression('AbsPref'), expression('Freq'), expression('ObsPref:Freq'), expression('AbsPref:Freq'))) +
 # ylim(c(-2.5, 10)) +
  ylab('Estimate') +
  xlab('Beta Coefficient Variable')

full_plot

#ggsave('../Data/full_plot.png')
```

### Reweighting generative preferences

One possibility is that LLMs have learned to weight the generative constraints differently than humans. In this section, we re-weight the generative preferences per LLM preferences, and then run another set of models with the updated generative constraints.

#### Re-weighted constraints

##### GPT2

```{r}
options(contrasts = c("contr.sum","contr.sum"))


prior_probs = c(
  prior(student_t(3, 0, 1), class = 'Intercept'),
  #prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(3, 0, 1), class = 'b')
)

gpt2_data_just_binoms = gpt2_data_just_binoms %>%
  rename('Stress' = `*BStress`) %>%
  # mutate_each_(funs(factor(.)), c('Form', 'Percept', 'Culture', 'Power', 'Intense', 'Icon', 'Len', 'Lapse', 'Stress')) %>%
  mutate(AlphaPref = ifelse(`Alpha Probs` > `Nonalpha Probs`, 1, 0))

reweighted_model_gpt = brm(data = gpt2_data_just_binoms,
                       AlphaPref ~ Form + Percept + Power + Icon + Len + `Stress` + Freq,
                       family = bernoulli(link = 'logit'),
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       control = list(adapt_delta=0.99, max_treedepth = 15),
                       prior = prior_probs,
                       #control = list(max_treedepth = 20),
                       file = '../Data/gpt2_reweighted_constraints'
                      )

fixef(reweighted_model_gpt)


```

##### GPT2-XL

```{r}
options(contrasts = c("contr.sum","contr.sum"))

gpt2xl_data_just_binoms = gpt2xl_data_just_binoms %>%
  rename('Stress' = `*BStress`) %>%
  # mutate_each_(funs(factor(.)), c('Form', 'Percept', 'Culture', 'Power', 'Intense', 'Icon', 'Len', 'Lapse', 'Stress')) %>%
  mutate(AlphaPref = ifelse(`Alpha Probs` > `Nonalpha Probs`, 1, 0))

reweighted_model_gptxl = brm(data = gpt2xl_data_just_binoms,
                       AlphaPref ~ Form + Percept + Power + Icon + Len + `Stress` + Freq,
                       family = bernoulli(link = 'logit'),
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       control = list(adapt_delta=0.99, max_treedepth = 15),
                       prior = prior_probs,
                       #control = list(max_treedepth = 20),
                       file = '../Data/gpt2xl_reweighted_constraints'
                      )

fixef(reweighted_model_gptxl)
```

##### Llama-7b

```{r}
options(contrasts = c("contr.sum","contr.sum"))

llama7b_data_just_binoms = llama7b_data_just_binoms %>%
  rename('Stress' = `*BStress`) %>%
  # mutate_each_(funs(factor(.)), c('Form', 'Percept', 'Culture', 'Power', 'Intense', 'Icon', 'Len', 'Lapse', 'Stress')) %>%
  mutate(AlphaPref = ifelse(`Alpha Probs` > `Nonalpha Probs`, 1, 0))

reweighted_model_llama7b = brm(data = llama7b_data_just_binoms,
                       AlphaPref ~ Form + Percept + Power + Icon + Len + `Stress` + Freq,
                       family = bernoulli(link = 'logit'),
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       prior = prior_probs,
                       file = '../Data/llama7b_reweighted_constraints'
                      )

fixef(reweighted_model_llama7b)
```

##### Llama-13b

```{r}
options(contrasts = c("contr.sum","contr.sum"))

llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  rename('Stress' = `*BStress`) %>%
  # mutate_each_(funs(factor(.)), c('Form', 'Percept', 'Culture', 'Power', 'Intense', 'Icon', 'Len', 'Lapse', 'Stress')) %>%
  mutate(AlphaPref = ifelse(`Alpha Probs` > `Nonalpha Probs`, 1, 0))


reweighted_model_llama13b = brm(data = llama13b_data_just_binoms,
                       AlphaPref ~ Form + Percept + Power + Icon + Len + `Stress` + Freq,
                       family = bernoulli(link = 'logit'),
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       prior = prior_probs,
                       file = '../Data/llama13b_reweighted_constraints'
                      )

fixef(reweighted_model_llama13b)
```

#### Humans vs Models

<!--# these models aren't converging, not sure what to do -->

Preparing data:

```{r}


prior_probs = c(
  prior(student_t(2, 0, 0.5), class = 'Intercept'),
  #prior(student_t(3, 0, 1), class = 'sigma'),
  prior(student_t(2, 0, 0.5), class = 'b'),
  prior(student_t(2, 0, 0.5), class = 'sd')
  #prior(student_t(3, 0, 1), class = 'sigma')
)



human_data = read_csv('../Data/data_2afc.csv') %>% #using the 2afc data from the preprint, will need to cite
  separate(UnorderedBinomial, sep = ',', into = c('WordA', 'WordB'), remove = F) %>%
  mutate(WordA = tolower(WordA), WordB = tolower(WordB)) %>%
  mutate(data_type = 'human') %>%
  rename(Stress = 'FinalStress') %>%
  rename(AlphaPref = 'response')

gpt2_data_just_binoms = gpt2_data_just_binoms %>%
  mutate(data_type = 'llm')
gpt2xl_data_just_binoms = gpt2xl_data_just_binoms %>%
  mutate(data_type = 'llm')
llama7b_data_just_binoms = llama7b_data_just_binoms %>%
  mutate(data_type = 'llm')
llama13b_data_just_binoms = llama13b_data_just_binoms %>%
  mutate(data_type = 'llm')

human_data_gpt2 = human_data %>%
  full_join(gpt2_data_just_binoms, by = c('WordA', 'WordB', 'AlphaPref', 'Len', 'Lapse', 'Stress', 'Freq', 'Form', 'Percept', 'Power', 'Icon', 'Culture', 'Intense', 'data_type')) %>%
  filter(WordA %in% (split(WordA, data_type) %>% reduce(intersect))) %>%
  ungroup() %>%
  group_by(WordA, WordB) %>%
  mutate(Item = cur_group_id()) %>%
  select(-item)

human_data_gpt2xl = human_data %>%
  full_join(gpt2xl_data_just_binoms, by = c('WordA', 'WordB', 'AlphaPref', 'Len', 'Lapse', 'Stress', 'Freq', 'Form', 'Percept', 'Power', 'Icon', 'Culture', 'Intense', 'data_type'))  %>%
  filter(WordA %in% (split(WordA, data_type) %>% reduce(intersect))) %>%
  ungroup() %>%
  group_by(WordA, WordB) %>%
  mutate(Item = cur_group_id()) %>%
  select(-item)

human_data_llama7b = human_data %>%
  full_join(llama7b_data_just_binoms, by = c('WordA', 'WordB', 'AlphaPref', 'Len', 'Lapse', 'Stress', 'Freq', 'Form', 'Percept', 'Power', 'Icon', 'Culture', 'Intense', 'data_type'))  %>%
  filter(WordA %in% (split(WordA, data_type) %>% reduce(intersect))) %>%
  ungroup() %>%
  group_by(WordA, WordB) %>%
  mutate(Item = cur_group_id()) %>%
  select(-item)

human_data_llama13b = human_data %>%
  full_join(llama13b_data_just_binoms, by = c('WordA', 'WordB', 'AlphaPref', 'Len', 'Lapse', 'Stress', 'Freq', 'Form', 'Percept', 'Power', 'Icon', 'Culture', 'Intense', 'data_type'))  %>%
  filter(WordA %in% (split(WordA, data_type) %>% reduce(intersect))) %>%
  ungroup() %>%
  group_by(WordA, WordB) %>%
  mutate(Item = cur_group_id()) %>%
  select(-item)
```

##### Humans

```{r}
options(contrasts = c("contr.sum","contr.sum"))

human_prefs = brm(data = human_data,
                       AlphaPref ~ (Form + Percept + Power + Icon + Len + `Stress` + Freq) + (1|item) + (1|subj),
                       family = bernoulli(link = 'logit'),
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(max_treedepth = 15),
                       prior = prior_probs,
                       #control = list(max_treedepth = 20),
                       file = '../Data/human_prefs'
                      )

fixef(human_prefs)
```

Quick plot of human vs LLM results:

```{r}

beta_coef_labels = c('Intercept', 'Form', 'Freq', 'Icon', 'Len', 'Percept', 'Power', 'Stress')
levels = c('b_Intercept', 'b_Form', 'b_Freq', 'b_Icon', 'b_Len', 'b_Percept', 'b_Power', 'b_Stress')


human_data_coefs_plot = human_prefs %>%
  gather_draws(b_Intercept, b_Form, b_Percept, b_Power, b_Icon, b_Len, b_Stress, b_Freq) %>%
  ggplot(aes(x = .value, y = factor(.variable, level = levels))) +
  stat_halfeye() +
  xlab('Posterior Distribution') +
  ylab('Beta Coefficent for each fixed-effect') +
  scale_y_discrete(labels = beta_coef_labels) + 
  xlim(-2, 2) +
  theme_bw()

reweighted_model_llama13b_plot = reweighted_model_llama13b %>%
  gather_draws(b_Intercept, b_Form, b_Percept, b_Power, b_Icon, b_Len, b_Stress, b_Freq) %>%
  ggplot(aes(x = .value, y = factor(.variable, level = levels))) +
  stat_halfeye() +
  xlab('Posterior Distribution') +
  ylab('Beta Coefficent for each fixed-effect') +
  scale_y_discrete(labels = beta_coef_labels) + 
  ggtitle('llama2 13b') +
  xlim(-2, 2) +
  theme_bw()

ggarrange(human_data_coefs_plot, reweighted_model_llama13b_plot, nrow = 1)
```

Human vs GPT-2

```{r}
beta_coef_labels = c('Intercept', 'Form', 'Freq', 'Icon', 'Len', 'Percept', 'Power', 'Stress')
levels = c('b_Intercept', 'b_Form', 'b_Freq', 'b_Icon', 'b_Len', 'b_Percept', 'b_Power', 'b_Stress')


human_data_coefs_plot = human_prefs %>%
  gather_draws(b_Intercept, b_Form, b_Percept, b_Power, b_Icon, b_Len, b_Stress, b_Freq) %>%
  ggplot(aes(x = .value, y = factor(.variable, level = levels))) +
  stat_halfeye() +
  xlab('Posterior Distribution') +
  ylab('Beta Coefficent for each fixed-effect') +
  scale_y_discrete(labels = beta_coef_labels) + 
  ggtitle('human prefs') +
  xlim(-2, 2) +
  theme_bw()

reweighted_model_gpt2_plot = reweighted_model_gpt %>%
  gather_draws(b_Intercept, b_Form, b_Percept, b_Power, b_Icon, b_Len, b_Stress, b_Freq) %>%
  ggplot(aes(x = .value, y = factor(.variable, level = levels))) +
  stat_halfeye() +
  xlab('Posterior Distribution') +
  ylab('Beta Coefficent for each fixed-effect') +
  scale_y_discrete(labels = beta_coef_labels) + 
  ggtitle('gpt-2') +
  xlim(-2, 2) +
  theme_bw()

ggarrange(human_data_coefs_plot, reweighted_model_gpt2_plot, reweighted_model_llama13b_plot, nrow = 1)
```

##### GPT2

```{r}
# options(contrasts = c("contr.sum","contr.sum"))
# 
# human_llm_gpt2 = brm(data = human_data_gpt2,
#                        AlphaPref ~ (Form + Percept + Power + Icon + Len + `Stress` + Freq) * data_type + (1|data_type) + (1|Item),
#                        family = bernoulli(link = 'logit'),
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        control = list(max_treedepth = 15),
#                        prior = prior_probs,
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/human_llm_gpt2'
#                       )
# 
# fixef(human_llm_gpt2)
```

##### GPT2-XL

```{r}
# options(contrasts = c("contr.sum","contr.sum"))
# 
# human_llm_gpt2xl = brm(data = human_data_gpt2xl,
#                        AlphaPref ~ (Form + Percept + Power + Icon + Len + `Stress` + Freq) * data_type + (1 + Item|data_type) + (1|Item),
#                        family = bernoulli(link = 'logit'),
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        prior = prior_probs,
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/human_llm_gpt2xl'
#                       )
# 
# fixef(human_llm_gpt2xl)
```

##### Llama-7b

```{r}
# options(contrasts = c("contr.sum","contr.sum"))
# 
# human_llm_llama7b = brm(data = human_data_llama7b,
#                        AlphaPref ~ (Form + Percept + Power + Icon + Len + `Stress` + Freq) * data_type + (1 + Item|data_type) + (1|Item),
#                        family = bernoulli(link = 'logit'),
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        prior = prior_probs,
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/human_llm_llama7b'
#                       )
# 
# fixef(human_llm_llama7b)
```

##### Llama-13b

```{r}
# options(contrasts = c("contr.sum","contr.sum"))
# 
# human_llm_llama13b = brm(data = human_data_llama13b,
#                        AlphaPref ~ (Form + Percept + Power + Icon + Len + `Stress` + Freq) * data_type+ (1|data_type),# + (1 + Item||data_type) + (1||Item),
#                        family = bernoulli(link = 'logit'),
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        prior = prior_probs,
#                        #control = list(max_treedepth = 15),
#                        file = '../Data/human_llm_llama13b'
#                       )
# 
# fixef(human_llm_llama13b)
# 
# 
# mcmc_plot(human_llm_llama13b, type = 'trace')
#mcmc_plot(reweighted_model_llama13b, type = 'dens')
```
