\pagenumbering{arabic}

# Introduction

How much of language is memorized and how much is improvised? Every time we speak, we are faced with the choice between familiar expressions, like *I don't know*, and novel constructions, like *to me it is uncertain*. In other words, we constantly navigate a trade-off between stored, item-specific knowledge – our stored knowledge of particular words and phrases – and abstract knowledge, which allows us to combine those stored representations in new ways.

From a young age, humans are capable of generating sentences that they've never encountered before [@kapatsinski2018; @berkoChildsLearningEnglish1958]. This ability is largely enabled by our ability to store forms that we've learned and compute new forms by applying knowledge of the grammar to these stored forms [@stembergerAreInflectedForms2004; @stembergerFrequencyLexicalStorage1986; @morganAbstractKnowledgeDirect2016; @morganModelingIdiosyncraticPreferences2015; @berkoChildsLearningEnglish1958]. In theory, these can be complementary forces: if a form is stored, it does not need to be computed, and if a form can be computed, it does not have to be stored. For example, if the word *cats* is stored, then it is not necessary to compute it (e.g., by combining the lexical root, *cat*, with a general plural rule, -*s*). On the other hand, if it can be computed (e.g., we have learned the word *cat*, and we have learned how to make regular forms plural in English), then we do not need to store it. However, there may be advantages to storing words or phrases that we can compute. For example, if we are producing a combination of words often enough (e.g., *bread and butter*), it may be efficient to store it in memory and retrieve the stored representation instead of composing it every time.

Traditional linguistic theories have assumed that very little is stored and instead a great deal of language leverages humans' remarkable ability to generate complex meaning by composing words together [@chomsky1965]. This was based on an assumption that human memory is limited and storing items that could be generated compositionally would be a waste of memory. These theories posit that words are stored and non-idiomatic phrases are generated compositionally. Holistic storage of multi-word phrases was reserved for idioms [@chomsky1965] and perhaps extremely high-frequency items [@pinker2002]. According to these theories, *I don't know* would be generated by accessing the individual words and then combining the individual representations together. On the other hand, usage-based theories have long posited the possibility of multi-word phrases being stored holistically [e.g., @bybee2001, @bybee2003, @stembergerAreInflectedForms2004, @stembergerFrequencyLexicalStorage1986, @kapatsinski2018, @morgan2015, @morganAbstractKnowledgeDirect2016, @morgan2024]. These theories posit that multi-word phrases can be stored if they're used often enough. According to these theories, a high-frequency phrase like *I don't know* is stored holistically while lower and mid-frequency phrases are generated compositionally.

## Evidence of Storage

There is a great deal of evidence that multi-word phrases are stored holistically. For example, high-frequency phrases such as *I don't know* undergo phonetic reduction that isn't seen in other low or mid-frequency phrases containing *don't* [@bybeeEffectUsageDegrees1999], suggesting that *I don't know* has a holistic representation separate from each of the individual words. If it was the case that the representation of *don't* in *I don't know* was the same as the representation of *don't* in other contexts then one would expect to see *don't* equally reduced in both cases. Similar to the results from @bybeeEffectUsageDegrees1999, @yiEumun2002 found evidence for holistic storage in Korean as well. In Korean, certain consonants undergo tensification when they occur after the future tense marker -*l*. @yiEumun2002 demonstrated that the rate of this tensification is higher in high-frequency phrases than low-frequency phrases, suggesting that they have a separate representation. Additionally, @bybee2003 demonstrated that there are many high-frequency phrases that undergo phonetic reduction that isn't accounted for by phonetic reduction of the words outside of those phrases ( e.g., *going to*, *have to*, *want to*, etc). These results parallel findings on a word-level (which most theories posit have separate representations). For example, in Korean epenthesis (insertion of a sound) occurs more often in high-frequency words than in low-frequency words [@leeFrequencyEffectsMorphologisation2015]. Similarly, deletion is more likely to occur in a frequent word like *most* than in an infrequent word like *mast* [@kapatsinskiHierarchicalInferenceSound2021, @bybeeWordFrequencyContext2002].

There's also an abundance of evidence for multi-word holistic storage from the Psycholinguistics literature. For example, frequent binomial phrases (e.g., *cat and dog*) are read faster in their frequent ordering than in their infrequent ordering [@siyanova-chanturiaSeeingPhraseTime2011]. Further, these ordering preferences are not due to generative preferences (such as a preference for frequent words first), but are driven by humans' experience with that specific item [@morgan2015, @morgan2024, @morganAbstractKnowledgeDirect2016]. Similarly, even after accounting for the frequency of the individual words, frequent multi-word phrases are read faster [@arnonMoreWordsFrequency2010] and produced faster [@janssenPhraseFrequencyEffects2012].

Additionally, there is evidence of holistic storage from the learning literature [@siegelmanAdvantageStartingBig2015, @bannardStoredWordSequences2008, @odonnellProductivityReuseLanguage2016]. For example, there is evidence that attending to the whole utterance as opposed to attending to each individual word facilitates learning [@siegelmanAdvantageStartingBig2015]. Additionally, in modeling learning of the English past tense, models that store some items holistically outperform models that don't [@odonnellProductivityReuseLanguage2016]. Specifically, @odonnellProductivityReuseLanguage2016 tested 4 probabilistic models on their ability to learn the English past tense. These models differed in whether they stored items holistically or composed them using morphological knowledge. They found that their inference-based model, which stored units of varying sizes, was able to learn the English past tense much better than the other models.

Further, there is also evidence of multi-word storage from the learning literature [@siegelman2015; @bannardStoredWordSequences2008]. For example, @siegelman2015 demonstrated that learning is facilitated by attending to the whole utterance, as opposed to attending to each individual word. Specifically, they used an artificial language paradigm to examine adult L2 learners' ability to learn grammatical gender. They found that adults learn grammatical gender better when they are presented with unsegmented utterances rather than segmented utterances. In other words, attending to the entire utterance, rather than learning to compose the utterance word-by-word, facilitated their learning. It seems plausible that if the entire utterance is being attended to, then participants may be learning (i.e., storing) the entire utterance initially. Further, storing larger-than-word chunks may possibly be facilitating the learning of grammatical gender in their study.

However, while there is an abundance of evidence that a lot more is stored than was previously considered, there are still a number of open questions. What factors drive storage? Frequent items are stored, but what about predictable items? Additionally, how are stored items represented? Do they retain the internal structure with respect to the individual words or morphemes? Further, how are stored multi-word phrases processed? Speech is inherently linear such that listeners always hear phrases word-by-word. How does that interact with multi-word representations such as *I don't know*?

## Factors that Drive Storage 

Despite the evidence of multi-word holistic storage, it is still unclear what drives storage. Specifically, humans are sensitive to both frequency and predictability. However, very few studies have examined the role of predictability in multi-word holistic storage [c.f., @odonnellFragmentGrammarsExploring2009]. Indeed, frequency seems to be assumed to be the driving factor behind holistic storage, with nearly every example given thus far in this dissertation being an example of frequency-driven holistic storage.

Predictability, however, plays an important part in many linguistic theories, especially the learning literature [@kapatsinski2018, @olejarczukDistributionalLearningErrordriven2018, @saffranStatisticalLearning8MonthOld1996, @ramscarChildrenValueInformativity2013]. For example, learners try to actively predict upcoming sounds when learning new phonetic categories [@olejarczukDistributionalLearningErrordriven2018]. Additionally, learners are highly sensitive to predictability when segmenting the speech stream into words [@saffranStatisticalLearning8MonthOld1996]. Thus if predictability drives what we learn, it seems quite plausible that it also may drive what we store.

## Representations of Storage

In addition to asking what humans store, it's also equally important to examine how stored items are represented. Specifically, do stored representations maintain internal structure with respect to their component parts. For example, @kapatsinskiFrequencyEmergencePrefabs2009 argued that they may lose some amount of their internal structure. They examined listener's reaction time when recognizing *up* inside phrases that varied in their frequency. They found that in high frequency V+*up* constructions it is harder to recognize *up* than in medium frequency phrases, even after accounting for phonetic reduction. This decrease in recognition time suggests 1) that high frequency V+*up* phrases are stored holistically (since participants should be faster to recognize words in high-frequency contexts if they are forming them compositionally) and 2) holistically stored items do not retain their internal structure.

A visualization of what this may look like is demonstrated in @fig-nointernalstructure. The left tree represents the phrase *pick up* stored holistically but with intact internal structure and the right tree represents the phrase *pick up* stored holistically but without internal structure.

![A visualization of a holistically stored phrase with internal structure (left) and without internal structure (right).](Figures/syntax_tree.png){#fig-nointernalstructure}

This lack of internal structure could be lost over time, or it may simply not have been learned in the first place. For example, much of children's early learning is driven by memorized chunks [@bybee2003, @tomaselloConstructingLanguageUsagebased2005]. For example, @tomaselloConstructingLanguageUsagebased2005 argued that young children learn verbs in fixed "islands", occurring in very fixed-constructions before eventually learning to generalize them to other contexts. Additionally, if predictability drives word-segmentation, many predictable phrases may be segmented as a single chunk. Further, @bybee2003 argued that after learning these chunks, it seems unlikely that children would then flush these from their memory. Further, many high frequency and high predictability phrases have semantically vague relationships (e.g., *trick or treat*). These phrases may be difficult to breakdown into their component words due to the lack of semantic transparency. Thus children may learn to store these phrases holistically. However, it is possible that their representations for these items are updated to reflect knowledge of the individual words upon further learning. Thus it is not entirely clear if holistically stored items lack internal representations of the individual words.

On the other hand, internal structure could be lost over time. For example, learners are more likely to semantically extend frequent forms to novel contexts than infrequent forms [@harmonPuttingOldTools2017]. This increase in accessibility may similarly drive their loss of internal structure over time: as a phrase is extended to new contexts, the representation of that phrase may also become more general to accommodate the new context. This may lead to the internal structure being lost over time as the contexts that the phrase is used in becomes more different from the contexts in which the individual words are used.

## Processing Consequences of Storage

## Storage in Humans vs Large Language Models

## Present Dissertation
